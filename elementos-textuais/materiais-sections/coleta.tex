\section{Coletando Base de Dados}
A primeira etapa do processo inclui coletar dados para que, posteriormente, seja possível mineirar atributos dentro deles. O coletor é algo simples, basicamente um \textit{script} que roda de tempos em tempos baseado na configuração apresentada. Foi desenvolvida uma função responsável por coletar em tempo real tweets em uma determinada área e que em seu corpo tivesse uma ou mais palavras chaves. Com isso é possível pesquisar um usuário e seus últimos 200 tweets.

De todos os modelos previamente explicados, os utilizados dentro do coletor são os de \textit{user} e \textit{tweet}. Eles podem ser encontrados dentro de \textit{dumont/collector/schemas}. Antes do dado ser salvo é possível notar a criação de um objeto partindo do atributo de texto referente ao tweet. Um dos problemas durante a mineração de dados é o uso de \textit{emojis} em textos. Sabendo que \textit{emojis} podem expressar sentimentos, armazenar e tratar esses dados poderia ser relevante na hora de confirmar o sentimento em frases, durante esse processo a lógica para localizar e extrair esses elementos foi abstraida para uma biblioteca chamada \textit{Emojinator}\footnote{https://github.com/getdumont/emojinator}. Além do texto tratado, também será obtida informações do \textit{emojis} utilizados no meio do texto.

Para ativar o coletor foi criado um CLI\footnote{CLI é abreviatura para \textit{Command Line Interface}, em outras palavras, uma interface que permite executar códigos direto do terminal}. Antes de rodar o comando é necessário configurar o projeto conforme o \autoref{app:configuracoes}. Após terminar a configuração deve ser executado o comando \textit{docker-compose up collector}, logo que finalizar a coleta vai preencher o MongoDB com os dados necessários para as próximas etapas. Durante essa pesquisa o comando foi rodado diversas vezes em um periodo de tempo, para criar uma base inicial. Vale lembrar que a idéia final se consiste em um mapeando periódico de perfis, porém nesse momento o coletor foi feito unicamente para juntar um aglomerado de dados indiferente de seus perfis.

No primeiro momento que o coletor foi rodado na pesquisa, foram coletados um total de 68583 tweets distribuídos entre 419 perfis, gerando uma média de aproximadamente 163 tweets por usuário. A massa de dados é bem ampla e achar uma amostra que suprisse as necessidades poderia ser algo complexo. Para isso o enfoque inicial é localizar uma amostra com os perfis que contem a maior massa de tweets negativos, entretanto, isso não é possível sem idealizar uma segunda parte do processo, no caso o pré-processamento e a mineração.
