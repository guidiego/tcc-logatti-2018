\subsection{Algoritimos de Machine Learning}
É essencial entender que existem vários algoritmos de aprendizagem, para todos os tipos já apresentados durante esse referencial. Entretanto, iremos salientar alguns deles.

Um dos algoritimos é o \textit{\textbf{support vector machine}} ou \textbf{SVM}, ele se consiste em construir o máximo de separação entre os pontos, os vetores do SVN possibilitam que, por mais que o algoritmo trabalhe muito bem linearmente, ele crie separações em maiores dimensões. Por ultimo, sua maior vantagem é a flexibilidade, SVN pode suportar funções complexas, porem, é totalmente resistente a \textit{overfitting} \cite[744]{russel2003artificial}.

Diferente de traçar vetores afim de estabelecer funções, existem métodos baseados em sequenciar varias unidades de processamento (similares aos agentes), afim de propagar um input e processa-lo N vezes, por N fórmulas diferentes, afim de encontrar o melhor modelo possível a partir do dado de saída. Basear-se em camadas de unidade de processamento com a proposta de simular o comportamento do cérebro humano ao processar uma informação utilizando camadas de neurônios, essas unidades são fortemente coligadas uma vez que, todas as unidades de todas as camadas são obrigatoriamente interligadas. Essa abordagem ficou conhecida como \textbf{Redes Neurais} ou \textbf{\textit{Neural Network}} \cite{haykin2004comprehensive, russel2003artificial}.

Motivo de retorno dos estudos as Redes Neurais, e também, um dos fatores que podem ser custosos para essa abordagem, o \textbf{\textit{back-propagation}} é o termo utilizado para classificar o ato de ajustar os parâmetros de entrada da sua rede a partir dos dados de saída. Esse ajuste é feito de forma automatizada pela própria massa afim de tentar igualar o valor de saída ao valor esperado. Quando uma rede neural apresenta muitas camadas ela passa a ser considerada uma estrutura de profundida. Infelizmente, o back-propagation não funciona muito bem para redes neurais com muitas camadas. Uma alternativa para isso, seria que nem todos os neurônios fosse interligados, e que os dados tomassem fossem reduzidos por necessidades isoladas se tornando cada vez mais específicos afim de no final propor um conjunto de saidas para parametros esperados, essa abordagem ficou conhecida como \textit{Deep Learning} \cite{lecun2015deep}.

Indiferente da abordagem escolhida, é necessário um conjunto de dados para treinar sua máquina. Portanto, a extração desses dados e posteriormente sua manipulação, exploração e tratamento são essenciais para o sucesso da IA e dos resultados gerados por ela.


